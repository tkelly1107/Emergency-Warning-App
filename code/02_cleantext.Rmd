---
title: "Cleaning up text"
output: html_notebook
---
```{r read in library}
library(dplyr)
library(textshape)
library(lexicon)
library(textclean)
library(readr)
```

```{r read file and check text; takes approx. 2 hours to run}
all_apps_reviews_nodupes <- read_csv("all_apps_reviews_nodupes.csv")
check_text(all_apps_reviews_nodupes$content)
```

#replace contractions
```{r replace contractions}
textcleaning <- replace_contraction(all_apps_reviews_nodupes$content)
```
#drop empty & NA rows
```{r drop blank rows}
textcleaning <- textcleaning %>% 
  drop_empty_row() %>% 
  drop_NA()
textcleaning <- as.character(textcleaning$content)
```
```{r replace emoji}
#replace emoji with character equiv
textcleaning <- replace_emoji(textcleaning)
```
```{r replace emoticons}
#replace emoticons with character equiv
textcleaning <- replace_emoticon(textcleaning)
```
```{r replace elongated words}
#replace elongated words
textcleaning <- replace_word_elongation(textcleaning)
```
```{r remove url}
textcleaning <- replace_url(textcleaning)
```
```{r remove tag}
textcleaning <- replace_tag(textcleaning)
```
```{r replace slang; takes around 1 hr to run}
textcleaning <- replace_internet_slang(textcleaning)
```
```{r remove html}
textcleaning <- replace_html(textcleaning, symbol = FALSE)
```
#remove incomplete sentences nr
```{r remove incomplete sentences}
textcleaning <- replace_incomplete(textcleaning, replacement = "")
```

```{r replace email}
textcleaning <- replace_email(textcleaning, pattern = qdapRegex::grab("rm_email"), replacement = "",
  ...)
```
#save output
write.csv(df,"C:\\Users\\recon\\OneDrive - Nova Southeastern University\\Desktop\\Emergency Communication data\\Data\\filename.csv", row.names = TRUE)
